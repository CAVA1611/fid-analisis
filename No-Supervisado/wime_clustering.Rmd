---
title: "Analisis_No_Supervisado"
author: "Belen Paredes y Cesar Velasco"
date: "25/01/2021"
output:
  html_document: default
  pdf_document: default
  word_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

INTRODUCCIÓN

En este análisis no supervisado  se utiliza un  dataset de las variantes tintas del vino portugués Vinho[1], donde se desea optener grupos optimos a partir de las caracteristicas fisicas y quimicas

Introducción teórica

El clustering es una tarea que tiene como finalidad principal lograr el agrupamiento de conjuntos de objetos no etiquetados, para lograr construir subconjuntos de datos conocidos como Clusters.  

Métodos de clusterización de datos a utilizar: 

K-means: también utiliza las distancias entre puntos. Y agrupo los clusters según lo cerca que están de los centros de gravedad de los clusters. A priori, tienes que saber cuántos clusters vas a crear para que el algoritmos sepa dónde colocar cada punto.
Gaussian mixture models (GMM): utiliza modelos gaussianos o modelos de distribuciones normales de diferentes formas para que puedas crear grupos en forma de elipses. Para cada punto se le calcula la probabilidad de pertenencia a cada modelo gaussiano

GIT: https://github.com/CAVA1611/fid-analisis

```{r}

chooseCRANmirror(graphics=FALSE, ind=1)
knitr::opts_chunk$set(echo = TRUE)

#Paquetes vistos en clases

install.packages("dplyr")
library(dplyr)
install.packages("ggplot2")
library(ggplot2)

#Paquetes  consultados

install.packages("cluster")
library(cluster)
library(corrplot)
library(factoextra)
library(mclust) 
library(FactoMineR)
library(rattle) 
```



```{r}

#lectura del dataset winequality-red.csv

wine <- read.csv("winequality-red.csv")

```
Atributos

-fixed.acidity:       
-Volatile.acidity:
-Citric.acid:      
-Residual.sugar:       
-Chorides
-Free.sulfr: 
-Total.sulur:       
-Density:      
-Ph:         
-Sulphates:         
-Alcohol:         
-Quality


Se realiza la correlacion entre columnas para verificar cuales nos ayudaran a determinar de mejor manera la calidad de vino

```{r}
#Empezamos el algoritmo observando las variables con un matrixplot:

cor(wine$quality, wine$density)
cor(wine$quality, wine$alcohol)
cor(wine$quality, wine$pH)
cor(wine$quality, wine$sulphates)

# grafica de correlacion
correlations <- cor(wine) # correlation matrix
corrplot(correlations, method="circle") # corrplot
```
Segun se observa en la grafica, exite una mayor correlacion para determinar la mayor calidad del vino con los datos de la columna alcohol y sulphates


```{r}
plot(x=wine$sulphates, y=wine$alcohol)

#Seleccion de las columnas alcohol y sulphates

wine_s_a <- wine[,10:11]


```
Para determinar el valor optimo de k usaremos dos metodos:


```{r}

# #determinar el numero ideal de cluster grafica con el metodo  Metodo WSS


wss<- 0 
for (i in 1:12) {
  out <- kmeans(wine_s_a, centers = i, nstart = 20)
  wss[i] <- out$tot.withinss
}

plot(1:12, wss,type = "b", xlab = "# Cluster", ylab = "WSS")
```


```{r}
#determinar el numero ideal de cluster grafica con el metodo "gap_stat"
set.seed(678)
fviz_nbclust(wine_s_a, kmeans, 
             method = "gap_stat",
             nboot = 50)

```

```{r}

#Verificacion del numero de k con la funcion fviz_nbclust de la libreria library(factoextra)
set.seed(678)
fviz_nbclust(wine_s_a, kmeans, method = "wss") +
    geom_vline(xintercept = 4, linetype = 2)+
  labs(subtitle = "K")

```

Por medio de la grafica se verifica que el numero optimo para K es 4

```{r}

# k-means
wine_clus <- kmeans(wine_s_a, center= 4, nstart = 20) 
plot(wine_s_a, col=wine_clus$cluster)
points(wine_clus$centers, cex=2, col=12, pch=19)
clusplot(wine_s_a, wine_clus$cluster, color=TRUE, shade=TRUE)

#Funcion eclust a modo de comparacion y verificacion con la funcion kmeans
eclust(wine_s_a, "kmeans", graph = TRUE)

#Verificacion del numero de k para el clustering - para probar retirar el comentario de las dos lineas de codigo
#clust_e <- eclust(wine_s_a, "kmeans", graph = TRUE)
#fviz_gap_stat(clust_e$gap_stat)
```


```{r}
# GMM
gmm_wine = Mclust(wine_s_a, G = 4)
summary(gmm_wine, parameters = TRUE)
plot(gmm_wine, what = "classification")

```


CONCLUSION: 

1. El metodo GMM es el que mejor realiza el agrupamiento de las muestras, puesto que el metodo de K-means establece una fontera estricta para clasificar los datos  en los diferentes cluster, mientras que GMM evalua la probabilidad de cada muestra para pertenecer a un cluster.

2. Al agrupar en 4 cluster se podria clasificar al vino en calidad alta, moderada, baja y muy baja. 





Bibliografía

[1] Dataset   =  https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009

[2]Clustering =  https://conceptosclaros.com/que-es-clustering/

[3] GMM       =  https://towardsdatascience.com/gaussian-mixture-models-d13a5e915c8e

[4] Rattle    =  https://rstudio-pubs-static.s3.amazonaws.com/317830_dde0f80173c047a2badbbe8918e95048.html

